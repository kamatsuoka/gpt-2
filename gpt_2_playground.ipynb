{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-playground.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamatsuoka/gpt-2/blob/master/gpt_2_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI-HVDbQS9dF",
        "colab_type": "text"
      },
      "source": [
        "# GPT-2 Playground\n",
        "\n",
        "# Background\n",
        "In this notebook you can play around with the medium (**345M** parameter) version of **Open AI's GPT-2** model<br/>\n",
        "from the paper **[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lil_k1vVuEt-",
        "colab_type": "text"
      },
      "source": [
        "##1. Install Code and Data\n",
        "Download the model data and install Python libraries.   This will take a minute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3xukZiPcmov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c320ab16-79f1-4ad1-83a8-7036e72f8c93"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "basedir = '/content' # specific to colaboratory\n",
        "os.chdir(basedir)\n",
        "!rm -rf gpt-2\n",
        "!git clone -q https://github.com/kamatsuoka/gpt-2/\n",
        "os.chdir('gpt-2')\n",
        "sys.path.append(os.getcwd() + '/src')\n",
        "!pip3 --quiet install -r requirements.txt\n",
        "!python download_model.py 345M --quiet\n",
        "from src.conditional_samples import run_model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▉                         | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 20kB 30.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 30kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 40kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycov0bwftzie",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generate text\n",
        "\n",
        "Enter starting text and optionally change the numeric parameters below.<br>\n",
        "Then run the cell to generate text based on your starting text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPy6eE1aYEI",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ### Starting text:\n",
        "text = '' #@param {type:\"string\"}\n",
        "#@markdown ### Samples to generate:\n",
        "nsamples = 5 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "#@markdown ### Number of words per sample:\n",
        "length = 100 #@param {type:\"slider\", min:10, max:200, step:1}\n",
        "#@markdown ### Randomness:\n",
        "temperature = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown ### Diversity:\n",
        "top_k = 40 #@param {type:\"slider\", min:0, max:80, step:1}\n",
        "\n",
        "run_model(starting_text=text, nsamples=nsamples, temperature=temperature, top_k=top_k)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdwAXFicwMI1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}